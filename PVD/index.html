<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description" content="PVD">
  <meta name="keywords" content="...">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PVD</title>
 
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="offcanvas.css" rel="stylesheet">
	
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <title>One is All: Bridging the Gap Between Neural Radiance Fields Architectures with Progressive Volume Distillation</title>
 
</head>
	
<body>
<div class="jumbotron jumbotron-fluid">
    <div class="container"></div>
	<h1 class="nerf_title_v2">PVD</h1>
	<h2 class="nerf_subheader_v2">One is All: Bridging the Gap Between Neural Radiance Fields Architectures with Progressive Volume Distillation</h2>
   <!--<h2 class="nerf_title_v2">One is All: Bridging the Gap Between Neural Radiance Fields Architectures with Progressive Volume Distillation</h2>-->
<!--    <h2 class="nerf_title_v2">Tensorial Radiance Fields</h2>  -->
<!-- <h1 class="nerf_subheader_v2">One is All: Bridging </h1>  -->
<!--    <h2>TensoRF: Tensorial Radiance Fields</h2>  -->
         <h3 class="nerf_subheader_v2">(AAAI 2023)</h3>
<!--            <p class="abstract">A compact and efficent scene representation</p>  -->
    <hr>
    <p class="authors">
        <a href="https://github.io/"> Shuangkang Fang</a>,
        <a href="http://github.io/"> Weixin Xu</a>,
        <a href="http://github.io/"> Heng Wang</a>,
        <a href="https://github.io/"> Yi Yang</a>,
        <a href="https://github.io/"> Yufeng Wang</a>,
	<a href="https://zsc.github.io/"> Shuchang Zhou</a>

    </p>

    <!-- <div class="nerf_equal_v2"><span class="text-span_nerf">*</span><span class="text-span_nerf_star">*</span>Denotes Equal Contribution</div> -->

    </br></br>
    <div class="btn-group" role="group" aria-label="Top menu">
        <a class="btn btn-primary" href="https://arxiv.org/">Paper</a>
        <a class="btn btn-primary" href="https://github.com/">Code</a>
        <a class="btn btn-primary" href="review.pdf">Supply</a>
    </div>
</div>

<!--
<body>
<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">PVD Under Review</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://skfang.github.io">Shuangkang Fang</a><sup>1,2</sup>,</span>
            <span class="author-block">
              <a>Weixin Xu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Heng Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Yi Yang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a>Yufeng Wang</a><sup>2*</sup>,</span>
            <span class="author-block">                
              <a href="https://zsc.github.io/">Shuchang Zhou</a><sup>1</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Megvii &nbsp;&nbsp;</span>
            <span class="author-block"><sup>2</sup>Beihang University &nbsp;&nbsp;</span>
          </div>
          <h1 style="font-size:24px;font-weight:bold">AAAI Under Review</h1>
          <div class="column has-text-centered">
            <div class="publication-links">
             
              <span class="link-block">
                <a href="static/paper.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
		    
              <span class="link-block">
                <a href="http://arxiv.org/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              
               <span class="link-block">
                <a href="static/supp.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Supp</span>
                </a>
              </span>
              
              <span class="link-block">
                <a href="https://github.com/"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
-->
	
</section>
<section class="section">
  <div class="container">

    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-two-thirds">
        <h2 class="title is-2">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Neural Radiance Fields (NeRF) methods have proved effective as compact, high-quality and versatile representations for 3D scense, and enable downstream tasks such as editing, retrieval, navigation, etc.  
Various neural architectures are vying for the core data structure of NeRF, including the plain Multi-Layer Perceptron (MLP), sparse tensors, low-rank tensors, hash tables and their compositions. 
Each of these representations has its particular set of trade-offs. For example, the hash table based representations admit faster training and rendering but their lack of clear geometric meaning hampers downstream tasks like spatial-relation-aware editing. 
In this paper, we propose Progressive Volume Distillation (PVD), a systematic distillation method that allows any-to-any conversions between different neural architectures, including MLP, sparse or low-rank tensors, hash tables and their compositions. 
PVD consequently empowers downstream applications to optimally adapt the neural representations for the task in hand in a post hoc fashion. 
The conversions are fast, as distillation is progressively performed on different levels of volume representations, from shallower to deeper. We also employ special treatment of density volume to deal with its specific numerical instability problem.
Empirical evidences are presented to validate our method on the NeRF-Synthetic, LLFF and TanksAndTemples datasets. 
For example, with PVD, an MLP-based NeRF model can be distilled from a hash table-based Instant-NGP model at a 10X ~ 20X faster speed than being trained from scratch, while achieving superior level of sysnthesis quality.
          </p>

        </div>
      </div>
    </div>
  </div>
  <!--/ Abstract. -->

	<!--           
    <div data-anchor="slide1" class="section nerf_section">
        <div class="grey_container w-container">
            <h2 class="grey-heading_nerf">
                Abstract
            </h2>
            <p class="paragraph-3 nerf_text">
                We present a novel approach to model and reconstruct radiance fields.
                Unlike NeRF that uses pure MLPs,
                we consider the full volume field as a 4D tensor and propose to factorize the tensor into multiple compact low-rank tensor components for efficient scene modeling.
            </p>
            <div class="columns-5 w-row">
                <img src="img/teaser_v6.png" style="width:95%; margin-right:0px; margin-top:0px;">
            </div>
   
            <p class="paragraph-3 nerf_text">
                We model a scene (left) as a tensorial radiance field (right) using a set of vectors and matrices that describe scene appearance
                and geometry along their corresponding axes. These vector/matrix factors are used to compute volume density and
                view-dependent RGB color via vector-matrix outer products, leading to efficient radiance field reconstruction and realistic rendering.
                </br>
                We demonstrate that TensoRF with CP decomposition can achieve fast reconstruction with better rendering quality and even a smaller model size (<b>< 4MB</b>) than NeRF.
                Moreover, TensoRF with VM decomposition can further boost our rendering quality to outperform previous state-of-the-art methods and reduce the reconstruction time (<b>< 10min</b> only with standard PyTorch implementation).
            </p>     
            <h2 class="grey-heading_nerf">
                Method
            </h2>
            <p class="paragraph-3 nerf_text">
                We factorize radiance fields into compact components for scene modeling.
                To doso, we apply both the classic CP decomposition and a new vector-matrix (VM) decomposition; both are illustrated in following figure:
            </p>
            <div class="columns-5 w-row">
                <img src="img/tensor_factorizationpng.png" style="width:95%; margin-right:0px; margin-top:0px;">
            </div>
            <p class="paragraph-3 nerf_text">
                Left: CP decomposition, which factorizes atensor as a sum of vector outer products.
                Right: our vector-matrix decomposition, which factorizes a tensor as a sum of vector-matrix outer products.
                Please refer to our paper for more decomposition derails.
            </p>


            <div class="columns-5 w-row">
                <img src="img/pipeline.png" style="width:95%; margin-right:0px; margin-top:10px;">
            </div>

            <p class="paragraph-3 nerf_text">
                We now present our TensoRF representation and reconstruction. For each shading location <b>x</b> = (x,y,z), we use linearly/bilinearly sampled values from the vector (<b>v</b>)/matrix (<b>M</b>) factors to compute the corresponding trilinearly interpolated values of the tensor components.
                The density component values (A<sub>σ</sub>(x)) are summed to get the volume density directly (σ).
                The appearance values (A<sub>c</sub>(x)) are concatenated into a vector (⊕[A<sub>c</sub><sup style="margin-left:-8px">m</sup>(x)]<sub>m</sub>) that is then multiplied by an appearance matrix (<b>B</b>) and sent to the decoding function S for RGB color (c) regression.
                The decoding function S can be a Spherical Harmonic (SH) function or a fully-connected network (FCN).
            </p>
        </div>
    </div>
-->
	
</br></br>

<div class="grey_container w-container">
	<!-- -->
	<h2 class="title is-2">Method</h2>
	<p class="paragraph-3 nerf_text">
		Our method aims to achieve mutual conversions between different architectures based on Radiance Fields. The architectures we have derived
		formula include implicit representations like MLP in NeRF, explicit representations like sparse tensors in Plenoxels, and 
		two hybrid representations: hash tables (in INGP) and low-rank tensors (VM-decomposition in TensoRF). Once formulated, 
		any-to-any conversion between these architectures and their compositions is possible using PVD. 
	</p>
	<div align="center" style="margin-top:80px;" style="margin-bottom:120px;">
		<img style='height: auto; width: 125%; object-fit: contain' src="static/images/overview.png" alt="overview_image">
	</div> 	
	
	<p class="paragraph-3 nerf_text">
		Loss on intermediate volume representations (shown as double arrow symbol) like output of φ, 
		color and constrained density are used alongside the final rendered RGB volume to accelerate the distillation. 
	</p>
	<div align="center" style="margin-top:80px;" style="margin-bottom:120px;">
		<img style='height: auto; width: 35%; object-fit: contain' src="static/images/table_division.png" alt="overview_image">
	</div> 
	<p class="paragraph-3 nerf_text">
	    We observed that the implicit and explicit structures in the hybrid representation are naturally separated and correspond to different 
	    learning objectives. Therefore, we consider splitting a model into this similar expression forms so that different parts can 
	    be aligned during distillation just like descripted in the table above.
	</p>
</div>

<section class="section">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 align="center"  class="title is-2">Video Display</h2>

        <!-- Mutual-Conversion -->
        <h3 align="center" class="title is-4">Mutual-Conversion - lego </h3>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-centered">
          <video poster=""
                 id="replay-video"
		 autoplay
                 controls
		 muted
                 loop
                 width="53%"
		 height="53%">
            <source src="static/videos/video_mutual_lego_15fps.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- Mutual-Conversion -->

	<!-- Hash2others -->
        <h3 align="center" class="title is-4">VM2others - LLFF </h3>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-centered">
          <video poster=""
                 id="replay-video"
		 autoplay
                 controls
		 muted
                 loop
                 width="63%"
		 height="63%">
            <source src="static/videos/VM2others_llff_fps25_withTea.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- Hash2others -->
	  
	 <!-- Hash2others tanks -->
        <h3 align="center" class="title is-4">Hash2others - TanksAndTemples </h3>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-centered">
          <video poster=""
                 id="replay-video"
		 autoplay
                 controls
		 muted
                 loop
                 width="90%"
		 height="90%">
            <source src="static/videos/hash2others-1.2mul-tanks-withTea.mp4"
                    type="video/mp4">
          </video>
        </div>
        <!-- Hash2others tanks-->
	      
        <!-- Ours Finetuned vs. NeRF
        <h3 align="center" style="margin-top:80px;"  class="title is-4">Ingp2Nerf vs. NeRF </h3>
        <div class="content has-text-justified">
        </div>
        <div class="content has-text-centered">
          <video poster='static/images/nerf_ours_ft_preview.png'
                 id="replay-video"
                 controls
                 muted
                 width="75%">
            <source src="static/videos/video_mutual_lego_15fps.mp4"
                    type="video/mp4">
          </video>
        </div>
	-->
          
      </div>
    </div>
    <!--/ Animation. -->
  </div>
</section>



<section class="section" id="BibTeX">
  <div class="container content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
@inproceedings{pvd2023,
  author={Fang, Shuangkang and Xu, Weixin and Wang, Heng and Yang, Yi and Wang, Yufeng and Zhou, Shuchang},
  title={One is All: Bridging the Gap Between Neural Radiance Fields Architectures with Progressive Volume Distillation},
  booktitle={AAAI},
  year={2023}
}
</code></pre>
  </div>
</section>
    

<footer class="footer">
  <div align="center" class="container">
    <div class="columns is-centered">
        <div class="content">
            This website is borrowed from <a href="https://github.com/nerfies/nerfies.github.io">nerfies</a>.
        </div>
      </div>
    </div>
</footer>

</body>
</html>
